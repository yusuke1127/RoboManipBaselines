import torch
import torch.nn as nn
from torchvision.models import ResNet18_Weights, resnet18
from torchvision.ops.misc import FrozenBatchNorm2d


class MlpPolicy(nn.Module):
    """MLP policy with ResNet backbone."""

    def __init__(
        self,
        state_dim,
        action_dim,
        num_images,
        hidden_dim_list=None,
        state_feature_dim=512,
    ):
        if hidden_dim_list is None:
            hidden_dim_list = [512, 512]

        super().__init__()

        # Instantiate state feature extractor
        self.state_feature_extractor = nn.Sequential(
            nn.Linear(state_dim, state_feature_dim),
            nn.ReLU(),
            nn.BatchNorm1d(state_feature_dim),
        )

        # Instantiate image feature extractor
        resnet_model = resnet18(
            weights=ResNet18_Weights.DEFAULT, norm_layer=FrozenBatchNorm2d
        )
        self.image_feature_extractor = nn.Sequential(
            *list(resnet.children())[:-1]
        )  # Remove last layer
        image_feature_dim = resnet_model.fc.in_features

        # Instantiate linear layers
        combined_feature_dim = state_feature_dim + num_images * image_feature_dim
        linear_dim_list = [combined_feature_dim] + hidden_dim_list + [action_dim]
        linear_layers = []
        for linear_idx in range(len(linear_dim_list) - 1):
            input_dim = linear_dim_list[linear_idx]
            output_dim = linear_dim_list[linear_idx + 1]
            linear_layers += [nn.Linear(input_dim, output_dim)]
            if linear_idx < len(linear_dim_list) - 2:
                linear_layers += [nn.ReLU(), nn.BatchNorm1d(output_dim)]
        self.linear_layer_seq = nn.Sequential(*linear_layers)

        # Initialize weights
        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, nonlinearity="relu")
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

    def forward(self, state, images):
        batch_size, num_images, C, H, W = images.shape

        # Extract state feature
        state_feature = self.state_feature_extractor(
            state
        )  # (batch_size, state_feature_dim)

        # Extract image feature
        image_features = []
        for i in range(num_images):
            image_feature = self.image_feature_extractor(
                images[:, i]
            )  # (batch_size, image_feature_dim, 1, 1)
            image_feature = image_feature.view(
                batch_size, -1
            )  # (batch_size, image_feature_dim)
            image_features.append(image_feature)
        image_features = torch.cat(
            image_features, dim=1
        )  # (batch_size, num_images * image_feature_dim)

        # Apply linear layers
        combined_feature = torch.cat(
            [state_feature, image_features], dim=1
        )  # (batch_size, combined_feature_dim)
        action = self.linear_layer_seq(combined_feature)  # (batch_size, action_dim)

        return action
